{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "from test4 import model\n",
    "import sort_of_clevr2\n",
    "home = str(Path.home())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data\n",
    "train_size = 9800\n",
    "val_size = 200\n",
    "image_size = 75\n",
    "size = 5\n",
    "cloest = 3\n",
    "mode = 'val'\n",
    "# mode = 'train'\n",
    "DATA_PATH = home + '/data/sortofclevr2/' + '_'.join(map(str,[train_size,val_size, image_size, size, cloest]))\n",
    "FILE = 'sort-of-clevr2-{}.pickle'.format(mode)\n",
    "with open(os.path.join(DATA_PATH, FILE), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['181018182500rn', 'sortofclevr2', '500', '64', '0.0001', '2', 'inp', '3', '9800', '200', '75', '5', '3', 'cv', '24', '3', '2', '4', 'True', 'te', '8', '128', '1', 'hp', '128', '4', 'gt', '1000', '4', 'fp', '256', '2', '0.2', '3', 'test4']\n",
      "35\n",
      "4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d2381de3d5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mchannel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_layer\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgt_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_layer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchannel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_layer\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgt_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcv_layout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_stride\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgt_layout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgt_hidden\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'cv'"
     ]
    }
   ],
   "source": [
    "# model_type = 'test5'\n",
    "# MODEL_PATH = os.path.join(home, 'codes', 'rn', model_type, model_name)\n",
    "\n",
    "\n",
    "load_code = '181018182500rn_sortofclevr2_500_64_0.0001_2_inp_3_9800_200_75_5_3_cv_24_3_2_4_True_te_8_128_1_hp_128_4_gt_1000_4_fp_256_2_0.2_3_test4'\n",
    "load_name = 'conv.pt'\n",
    "print( load_code.split('_'))\n",
    "print(len(['181018182500rn', 'sortofclevr2', '500', '64', '0.0001', '2', 'inp', '3', '9800', '200', '75', '5', '3', 'cv', '24', '3', '2', '4', 'True', 'te', '8', '128', '1', 'hp', '128', '4', 'gt', '1000', '4', 'fp', '256', '2', '0.2', '3', 'test4']))\n",
    "\n",
    "name, dataset, epochs, batch_size, lr, device, \\\n",
    "_, channel_size, a,b,c, train_size, test_size, image_size, size, closest,\\\n",
    "_, cv_filter, cv_kernel, cv_stride, cv_layer, cv_layernorm,\\\n",
    "_, te_embedding, te_hidden, te_layer,\\\n",
    "_, gt_hidden, gt_layer,\\\n",
    "_, fp_hidden, fp_dropout, fp_dropout_rate, fp_layer,\\\n",
    "model_type = load_code.split('_')\n",
    "print(te_layer)\n",
    "\n",
    "channel_size, train_size, test_size, image_size, size, closest, cv_filter, cv_kernel, cv_stride, cv_layer, te_embedding, te_hidden, te_layer,  gt_hidden, gt_layer, fp_hidden, fp_layer = \\\n",
    "map(int, [channel_size, train_size, test_size, image_size, size, closest, cv_filter, cv_kernel, cv_stride, cv_layer, te_embedding, te_hidden, te_layer,  gt_hidden, gt_layer, fp_hidden, fp_layer])\n",
    "cv_layout = [(cv_filter, cv_kernel, cv_stride) for i in range(cv_layer)]\n",
    "gt_layout = [gt_hidden for i in range(gt_layer)]\n",
    "gt_layout.insert(0, (cv_filter + 2) * 2 + te_embedding * 2)\n",
    "fp_layout = [gt_hidden] + [fp_hidden for i in range(fp_layer - 1)] + [sort_of_clevr2.a_size]\n",
    "\n",
    "conv = model.Conv(input_h, input_w, cv_layout, channel_size, cv_layernorm).to(device)\n",
    "g_theta = model.MLP(gt_layout).to(device)\n",
    "f_phi = model.MLP(fp_layout).to(device)\n",
    "text_encoder = model.Text_embedding(train_loader.dataset.c_size, train_loader.dataset.q_size, te_embedding).to(device)\n",
    "# model_name = 'text_encoder.pt'\n",
    "# model_name = 'g_theta.pt'\n",
    "# model_name = 'f_phi.pt'\n",
    "\n",
    "LOAD_PATH = os.path.join(home, 'experiment', 'rn', load_code, load_name)\n",
    "LOAD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae584fd668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_num = 0\n",
    "image, nrel, rel = data[data_num]\n",
    "image\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
